{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune Sentence Transformer for Medical Symptom Extraction\n",
    "\n",
    "**Purpose:** Train a sentence transformer model to better understand how patients describe symptoms in natural language.\n",
    "\n",
    "**Dataset:** \n",
    "- 200k doctor-patient conversations (ai-medical-chatbot.csv)\n",
    "- 131+ canonical symptoms (symptoms.csv)\n",
    "\n",
    "**Output:** Fine-tuned model saved to `models/medical_symptom_matcher/`\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Installation](#setup)\n",
    "2. [Load Data](#load-data)\n",
    "3. [Prepare Training Data](#prepare-training)\n",
    "4. [Fine-Tune Model](#fine-tune)\n",
    "5. [Evaluate Performance](#evaluate)\n",
    "6. [Save Model](#save)\n",
    "7. [Quick Test](#test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Installation <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers torch pandas numpy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Setup\n",
    "import os\n",
    "\n",
    "# Create necessary directories\n",
    "!mkdir -p data models\n",
    "\n",
    "print(\"\ud83d\udcc1 Directories created!\")\n",
    "print(\"\\n\u26a0\ufe0f IMPORTANT: Upload your datasets now!\")\n",
    "print(\"   1. Click the folder icon on the left sidebar\")\n",
    "print(\"   2. Navigate to the 'data' folder\")\n",
    "print(\"   3. Upload these files:\")\n",
    "print(\"      - ai-medical-chatbot.csv\")\n",
    "print(\"      - symptoms.csv\")\n",
    "print(\"\\n\ud83d\udca1 Or use the code below to upload via dialog:\")\n",
    "print(\"\\nfrom google.colab import files\")\n",
    "print(\"uploaded = files.upload()\")\n",
    "print(\"# Then move files: !mv *.csv data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\u2705 GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No GPU detected. Training will be MUCH slower.\")\n",
    "    print(\"   Go to Runtime > Change runtime type > Select GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, InputExample, losses, evaluation\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     13\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     CrossEncoder,\n\u001b[0;32m     17\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     19\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\backend\\load.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _save_pretrained_wrapper, backend_should_export, backend_warn_to_save\n\u001b[0;32m     11\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\__init__.py:958\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m    956\u001b[0m _import_structure \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mset\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _import_structure\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m--> 958\u001b[0m import_structure \u001b[38;5;241m=\u001b[39m \u001b[43mdefine_import_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m import_structure[\u001b[38;5;28mfrozenset\u001b[39m({})]\u001b[38;5;241m.\u001b[39mupdate(_import_structure)\n\u001b[0;32m    961\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m _LazyModule(\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m     extra_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m: __version__},\n\u001b[0;32m    967\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:2867\u001b[0m, in \u001b[0;36mdefine_import_structure\u001b[1;34m(module_path, prefix)\u001b[0m\n\u001b[0;32m   2843\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[0;32m   2844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefine_import_structure\u001b[39m(module_path: \u001b[38;5;28mstr\u001b[39m, prefix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m IMPORT_STRUCTURE_T:\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \u001b[38;5;124;03m    This method takes a module_path as input and creates an import structure digestible by a _LazyModule.\u001b[39;00m\n\u001b[0;32m   2847\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2865\u001b[0m \u001b[38;5;124;03m    If `prefix` is not None, it will add that prefix to all keys in the returned dict.\u001b[39;00m\n\u001b[0;32m   2866\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2867\u001b[0m     import_structure \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2868\u001b[0m     spread_dict \u001b[38;5;241m=\u001b[39m spread_import_structure(import_structure)\n\u001b[0;32m   2870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:2580\u001b[0m, in \u001b[0;36mcreate_import_structure_from_path\u001b[1;34m(module_path)\u001b[0m\n\u001b[0;32m   2578\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(module_path):\n\u001b[0;32m   2579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(module_path, f)):\n\u001b[1;32m-> 2580\u001b[0m         import_structure[f] \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_import_structure_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2582\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, f)):\n\u001b[0;32m   2583\u001b[0m         adjacent_modules\u001b[38;5;241m.\u001b[39mappend(f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\import_utils.py:2604\u001b[0m, in \u001b[0;36mcreate_import_structure_from_path\u001b[1;34m(module_path)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2602\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 2604\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m   2605\u001b[0m     file_content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   2607\u001b[0m \u001b[38;5;66;03m# Remove the .py suffix\u001b[39;00m\n",
      "File \u001b[1;32m<frozen codecs>:309\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f Running on CPU - training will be slower but still works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data <a id='load-data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load symptoms list\n",
    "print(\"Loading symptoms...\")\n",
    "symptoms_df = pd.read_csv('symptoms.csv')\n",
    "SYMPTOMS = symptoms_df['symptoms'].str.lower().str.strip().tolist()\n",
    "print(f\"\u2713 Loaded {len(SYMPTOMS)} symptoms\")\n",
    "print(f\"\\nFirst 10 symptoms:\")\n",
    "for i, symptom in enumerate(SYMPTOMS[:10], 1):\n",
    "    print(f\"  {i}. {symptom}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load medical conversations\n",
    "print(\"\\nLoading medical conversations...\")\n",
    "print(\"\u26a0\ufe0f This may take a minute for 200k rows...\")\n",
    "\n",
    "conversations_df = pd.read_csv('ai-medical-chatbot.csv')\n",
    "print(f\"\u2713 Loaded {len(conversations_df):,} conversations\")\n",
    "print(f\"\\nDataset columns: {list(conversations_df.columns)}\")\n",
    "print(f\"\\nFirst conversation example:\")\n",
    "print(f\"Description: {conversations_df.iloc[0]['Description'][:100]}...\")\n",
    "print(f\"Patient: {conversations_df.iloc[0]['Patient'][:150]}...\")\n",
    "print(f\"Doctor: {conversations_df.iloc[0]['Doctor'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Prepare Training Data <a id='prepare-training'></a>\n",
    "\n",
    "We'll create positive training pairs where:\n",
    "- **Text 1:** Patient's message\n",
    "- **Text 2:** Symptom name\n",
    "- **Label:** 1.0 (if symptom mentioned), 0.0 (if not mentioned)\n",
    "\n",
    "This teaches the model to recognize when patient language matches a symptom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def extract_symptom_mentions(patient_text, doctor_text, symptoms_list):\n",
    "    \"\"\"\n",
    "    Find which symptoms are mentioned in the conversation\n",
    "    Returns list of mentioned symptoms\n",
    "    \"\"\"\n",
    "    patient_text = clean_text(patient_text)\n",
    "    doctor_text = clean_text(doctor_text)\n",
    "    combined_text = patient_text + \" \" + doctor_text\n",
    "    \n",
    "    mentioned_symptoms = []\n",
    "    \n",
    "    for symptom in symptoms_list:\n",
    "        symptom_clean = symptom.lower().strip()\n",
    "        \n",
    "        # Check exact match\n",
    "        if symptom_clean in combined_text:\n",
    "            mentioned_symptoms.append(symptom)\n",
    "            continue\n",
    "        \n",
    "        # Check word-by-word match (for multi-word symptoms)\n",
    "        symptom_words = symptom_clean.split()\n",
    "        if len(symptom_words) > 1:\n",
    "            # Check if all words appear in text (allows for different word order)\n",
    "            if all(word in combined_text for word in symptom_words):\n",
    "                mentioned_symptoms.append(symptom)\n",
    "    \n",
    "    return mentioned_symptoms\n",
    "\n",
    "# Test the function\n",
    "test_patient = \"I have a terrible headache and feel nauseous\"\n",
    "test_doctor = \"You may have migraine. The nausea is common with headaches.\"\n",
    "test_mentions = extract_symptom_mentions(test_patient, test_doctor, SYMPTOMS)\n",
    "print(f\"Test extraction: {test_mentions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_examples(conversations_df, symptoms_list, max_examples=50000, sample_negatives=True):\n",
    "    \"\"\"\n",
    "    Create training examples from conversations\n",
    "    \n",
    "    Args:\n",
    "        conversations_df: DataFrame with Patient, Doctor columns\n",
    "        symptoms_list: List of canonical symptoms\n",
    "        max_examples: Maximum number of positive examples to create\n",
    "        sample_negatives: Whether to include negative examples (no symptom match)\n",
    "    \n",
    "    Returns:\n",
    "        List of InputExample objects\n",
    "    \"\"\"\n",
    "    training_examples = []\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    \n",
    "    print(f\"\\nCreating training examples from {len(conversations_df):,} conversations...\")\n",
    "    print(f\"This will take 5-10 minutes...\\n\")\n",
    "    \n",
    "    for idx, row in tqdm(conversations_df.iterrows(), total=len(conversations_df)):\n",
    "        if positive_count >= max_examples:\n",
    "            break\n",
    "        \n",
    "        patient_text = clean_text(row['Patient'])\n",
    "        doctor_text = clean_text(row['Doctor'])\n",
    "        \n",
    "        # Skip very short messages\n",
    "        if len(patient_text.split()) < 5:\n",
    "            continue\n",
    "        \n",
    "        # Find mentioned symptoms\n",
    "        mentioned_symptoms = extract_symptom_mentions(patient_text, doctor_text, symptoms_list)\n",
    "        \n",
    "        if mentioned_symptoms:\n",
    "            # Create positive examples\n",
    "            for symptom in mentioned_symptoms:\n",
    "                training_examples.append(\n",
    "                    InputExample(texts=[patient_text, symptom], label=1.0)\n",
    "                )\n",
    "                positive_count += 1\n",
    "            \n",
    "            # Create some negative examples (symptoms NOT mentioned)\n",
    "            if sample_negatives and len(mentioned_symptoms) < len(symptoms_list):\n",
    "                # Sample 1-2 negative symptoms per positive\n",
    "                unmentioned = [s for s in symptoms_list if s not in mentioned_symptoms]\n",
    "                num_negatives = min(2, len(unmentioned))\n",
    "                negative_samples = np.random.choice(unmentioned, size=num_negatives, replace=False)\n",
    "                \n",
    "                for neg_symptom in negative_samples:\n",
    "                    training_examples.append(\n",
    "                        InputExample(texts=[patient_text, neg_symptom], label=0.0)\n",
    "                    )\n",
    "                    negative_count += 1\n",
    "    \n",
    "    print(f\"\\n\u2713 Created {len(training_examples):,} training examples\")\n",
    "    print(f\"  - Positive examples: {positive_count:,}\")\n",
    "    print(f\"  - Negative examples: {negative_count:,}\")\n",
    "    print(f\"  - Ratio: {positive_count/negative_count:.2f}:1 (positive:negative)\")\n",
    "    \n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples\n",
    "# Adjust max_examples based on your compute resources:\n",
    "# - CPU: 10,000-20,000 examples\n",
    "# - GPU: 50,000+ examples\n",
    "\n",
    "MAX_EXAMPLES = 30000  # Adjust this based on your hardware\n",
    "\n",
    "train_examples = create_training_examples(\n",
    "    conversations_df, \n",
    "    SYMPTOMS, \n",
    "    max_examples=MAX_EXAMPLES,\n",
    "    sample_negatives=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation\n",
    "train_data, val_data = train_test_split(train_examples, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Training: {len(train_data):,} examples\")\n",
    "print(f\"  Validation: {len(val_data):,} examples\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\n\ud83d\udcdd Sample training examples:\")\n",
    "for i in range(min(3, len(train_data))):\n",
    "    example = train_data[i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Patient text: {example.texts[0][:100]}...\")\n",
    "    print(f\"  Symptom: {example.texts[1]}\")\n",
    "    print(f\"  Label: {'MATCH \u2713' if example.label == 1.0 else 'NO MATCH \u2717'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Fine-Tune Model <a id='fine-tune'></a>\n",
    "\n",
    "We'll fine-tune the `all-MiniLM-L6-v2` model using cosine similarity loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model\n",
    "print(\"Loading base model...\")\n",
    "base_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(base_model_name)\n",
    "print(f\"\u2713 Loaded {base_model_name}\")\n",
    "print(f\"\\nModel embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=16)\n",
    "val_dataloader = DataLoader(val_data, shuffle=False, batch_size=16)\n",
    "\n",
    "# Define loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "print(f\"Training setup:\")\n",
    "print(f\"  Batch size: 16\")\n",
    "print(f\"  Training batches: {len(train_dataloader)}\")\n",
    "print(f\"  Validation batches: {len(val_dataloader)}\")\n",
    "print(f\"  Loss function: CosineSimilarityLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 3  # Usually 2-4 epochs is enough\n",
    "WARMUP_STEPS = int(len(train_dataloader) * 0.1)  # 10% of training data for warm-up\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Warmup steps: {WARMUP_STEPS}\")\n",
    "print(f\"  Total training steps: {len(train_dataloader) * NUM_EPOCHS}\")\n",
    "\n",
    "# Estimate training time\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n\u23f1\ufe0f Estimated time: {NUM_EPOCHS * 15}-{NUM_EPOCHS * 30} minutes on GPU\")\n",
    "else:\n",
    "    print(f\"\\n\u23f1\ufe0f Estimated time: {NUM_EPOCHS * 60}-{NUM_EPOCHS * 120} minutes on CPU\")\n",
    "    print(f\"   (Consider using Google Colab with GPU if this is too slow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "output_path = 'models/medical_symptom_matcher'\n",
    "\n",
    "print(f\"\\n\ud83d\ude80 Starting training...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=NUM_EPOCHS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    output_path=output_path,\n",
    "    show_progress_bar=True,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"\u2713 Training complete!\")\n",
    "print(f\"\u2713 Model saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Evaluate Performance <a id='evaluate'></a>\n",
    "\n",
    "Let's test the fine-tuned model against the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both models for comparison\n",
    "print(\"Loading models for comparison...\")\n",
    "base_model = SentenceTransformer(base_model_name)\n",
    "finetuned_model = SentenceTransformer(output_path)\n",
    "print(\"\u2713 Models loaded\")\n",
    "\n",
    "# Pre-compute symptom embeddings\n",
    "print(\"\\nComputing symptom embeddings...\")\n",
    "base_symptom_embeddings = base_model.encode(SYMPTOMS, convert_to_tensor=True, show_progress_bar=True)\n",
    "finetuned_symptom_embeddings = finetuned_model.encode(SYMPTOMS, convert_to_tensor=True, show_progress_bar=True)\n",
    "print(\"\u2713 Embeddings computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def extract_symptoms_comparison(text, model, symptom_embeddings, symptoms_list, threshold=0.5, top_k=5):\n",
    "    \"\"\"\n",
    "    Extract symptoms using a given model\n",
    "    \"\"\"\n",
    "    text_embedding = model.encode(text, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(text_embedding, symptom_embeddings)[0]\n",
    "    \n",
    "    matches = []\n",
    "    for idx, score in enumerate(similarities):\n",
    "        if score > threshold:\n",
    "            matches.append({\n",
    "                'symptom': symptoms_list[idx],\n",
    "                'score': float(score)\n",
    "            })\n",
    "    \n",
    "    matches = sorted(matches, key=lambda x: x['score'], reverse=True)[:top_k]\n",
    "    return matches\n",
    "\n",
    "# Test cases that previously failed\n",
    "test_cases = [\n",
    "    \"I've been sneezing all day\",\n",
    "    \"My head hurts really bad\",\n",
    "    \"I am coughing a lot\",\n",
    "    \"My stomach area has been itching like crazy\",\n",
    "    \"I can't stop sneezing and my nose is blocked\",\n",
    "    \"Having terrible pounding in my temples and feel nauseous\",\n",
    "    \"My back is really painful\",\n",
    "    \"I feel dizzy and want to throw up\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: BASE MODEL vs FINE-TUNED MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for test_text in test_cases:\n",
    "    print(f\"\\n\ud83d\udcdd Input: \\\"{test_text}\\\"\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Base model results\n",
    "    base_results = extract_symptoms_comparison(\n",
    "        test_text, base_model, base_symptom_embeddings, SYMPTOMS, threshold=0.45\n",
    "    )\n",
    "    print(\"\u274c BASE MODEL:\")\n",
    "    if base_results:\n",
    "        for r in base_results:\n",
    "            print(f\"   \u2022 {r['symptom']} (confidence: {r['score']:.3f})\")\n",
    "    else:\n",
    "        print(\"   \u2022 No symptoms detected\")\n",
    "    \n",
    "    # Fine-tuned model results\n",
    "    finetuned_results = extract_symptoms_comparison(\n",
    "        test_text, finetuned_model, finetuned_symptom_embeddings, SYMPTOMS, threshold=0.45\n",
    "    )\n",
    "    print(\"\\n\u2705 FINE-TUNED MODEL:\")\n",
    "    if finetuned_results:\n",
    "        for r in finetuned_results:\n",
    "            print(f\"   \u2022 {r['symptom']} (confidence: {r['score']:.3f})\")\n",
    "    else:\n",
    "        print(\"   \u2022 No symptoms detected\")\n",
    "    \n",
    "    # Calculate improvement\n",
    "    improvement = len(finetuned_results) - len(base_results)\n",
    "    if improvement > 0:\n",
    "        print(f\"\\n\ud83d\udca1 Improvement: +{improvement} more symptoms detected\")\n",
    "    elif improvement < 0:\n",
    "        print(f\"\\n\u26a0\ufe0f Note: {abs(improvement)} fewer symptoms (may be more precise)\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative evaluation on validation set\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUANTITATIVE EVALUATION ON VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def evaluate_model(model, symptom_embeddings, val_examples, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate model accuracy on validation set\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = len(val_examples)\n",
    "    \n",
    "    for example in tqdm(val_examples[:1000], desc=\"Evaluating\"):  # Sample 1000 for speed\n",
    "        text = example.texts[0]\n",
    "        target_symptom = example.texts[1]\n",
    "        true_label = example.label\n",
    "        \n",
    "        # Get prediction\n",
    "        text_embedding = model.encode(text, convert_to_tensor=True)\n",
    "        symptom_idx = SYMPTOMS.index(target_symptom)\n",
    "        similarity = float(util.cos_sim(text_embedding, symptom_embeddings[symptom_idx]))\n",
    "        \n",
    "        predicted_label = 1.0 if similarity > threshold else 0.0\n",
    "        \n",
    "        if predicted_label == true_label:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / min(1000, total)\n",
    "    return accuracy\n",
    "\n",
    "print(\"\\nEvaluating base model...\")\n",
    "base_accuracy = evaluate_model(base_model, base_symptom_embeddings, val_data)\n",
    "print(f\"Base model accuracy: {base_accuracy:.2%}\")\n",
    "\n",
    "print(\"\\nEvaluating fine-tuned model...\")\n",
    "finetuned_accuracy = evaluate_model(finetuned_model, finetuned_symptom_embeddings, val_data)\n",
    "print(f\"Fine-tuned model accuracy: {finetuned_accuracy:.2%}\")\n",
    "\n",
    "improvement_pct = ((finetuned_accuracy - base_accuracy) / base_accuracy) * 100\n",
    "print(f\"\\n\ud83c\udfaf Improvement: {improvement_pct:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Save Model & Metadata <a id='save'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "metadata = {\n",
    "    'base_model': base_model_name,\n",
    "    'training_examples': len(train_data),\n",
    "    'validation_examples': len(val_data),\n",
    "    'num_symptoms': len(SYMPTOMS),\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'base_accuracy': float(base_accuracy),\n",
    "    'finetuned_accuracy': float(finetuned_accuracy),\n",
    "    'improvement_pct': float(improvement_pct)\n",
    "}\n",
    "\n",
    "with open(f'{output_path}/training_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\u2713 Metadata saved to {output_path}/training_metadata.json\")\n",
    "print(f\"\\n\ud83d\udce6 Model package contents:\")\n",
    "print(f\"   {output_path}/\")\n",
    "for item in os.listdir(output_path):\n",
    "    print(f\"   \u251c\u2500\u2500 {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Quick Test Interface <a id='test'></a>\n",
    "\n",
    "Interactive testing of your fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_symptom_extraction(text, threshold=0.45, top_k=5):\n",
    "    \"\"\"\n",
    "    Test the fine-tuned model on custom input\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Input: \\\"{text}\\\"\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = extract_symptoms_comparison(\n",
    "        text, finetuned_model, finetuned_symptom_embeddings, \n",
    "        SYMPTOMS, threshold=threshold, top_k=top_k\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\n\u2705 Detected {len(results)} symptom(s):\\n\")\n",
    "        for i, r in enumerate(results, 1):\n",
    "            confidence_bar = '\u2588' * int(r['score'] * 20)\n",
    "            print(f\"  {i}. {r['symptom']}\")\n",
    "            print(f\"     Confidence: {r['score']:.3f} {confidence_bar}\")\n",
    "    else:\n",
    "        print(\"\\n\u274c No symptoms detected above threshold\")\n",
    "        print(f\"   Try lowering threshold (currently {threshold})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test it!\n",
    "test_symptom_extraction(\"I've been feeling dizzy and have a terrible headache\")\n",
    "test_symptom_extraction(\"My throat is sore and I can't stop coughing\")\n",
    "test_symptom_extraction(\"I have chest pain and shortness of breath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing (optional - uncomment to use)\n",
    "# while True:\n",
    "#     user_input = input(\"\\nDescribe your symptoms (or 'quit' to exit): \")\n",
    "#     if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "#         break\n",
    "#     test_symptom_extraction(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \u2705 Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Your fine-tuned model is saved at:** `models/medical_symptom_matcher/`\n",
    "\n",
    "2. **To use it in your chatbot notebook:**\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('models/medical_symptom_matcher')\n",
    "```\n",
    "\n",
    "3. **Integration code is ready** - just copy the `extract_symptoms_comparison()` function to your main chatbot!\n",
    "\n",
    "### Performance Summary:\n",
    "- \u2705 Base model accuracy: {base_accuracy:.1%}\n",
    "- \u2705 Fine-tuned accuracy: {finetuned_accuracy:.1%}\n",
    "- \u2705 Improvement: {improvement_pct:+.1f}%\n",
    "\n",
    "### Tips:\n",
    "- Adjust `threshold` parameter to control sensitivity (lower = more symptoms detected)\n",
    "- If you need better performance, train with more examples or more epochs\n",
    "- The model works best with complete sentences (not just single words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}